{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Necessary Library\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\n\nimport cv2\nfrom tqdm import tqdm\nimport io\nimport seaborn as sns\n\n# Shuffle arrays or sparse matrices in a consistent way\nfrom sklearn.utils import shuffle \nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\n\nfrom tensorflow.keras.applications import EfficientNetB0, EfficientNetB7\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard,ModelCheckpoint\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom keras.utils.vis_utils import plot_model\n\nimport ipywidgets as widgets\nfrom PIL import Image\nfrom IPython.display import display, clear_output\n\n#Extra functionality for TensorFlow\n#conda install -c esri tensorflow-addons\nimport tensorflow_addons as tfa\n\nfrom datetime import datetime\nfrom keras import regularizers\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\n\nprint(\"Importing Reference done..\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Variable declaration\nBASE_DIR = \"/kaggle/input/working-ds/AD_PD_DETECTION/ORIGINAL_AD_PD_DATA/\"\nSAVE_DIR = \"/kaggle/working/\"\n#SAVE_DIR = BASE_DIR + \"model_bilateral_smote_100_RMSprop_tr_001_141022_final/\"\n\n#Check the saved directory and create if not found\nisExist = os.path.exists(SAVE_DIR)\nif not isExist:\n   os.makedirs(SAVE_DIR)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = ['CONTROL', 'AD', 'PD']\nX_train = [] #Training Dataset\nY_train = [] #Training Labels\n\nX_train_img = [] #Training Dataset\nY_train_img = [] #Training Labels\n\nX_Test_AD = []\nY_Test_AD = []\nX_Test_PD = []\nY_Test_PD = []\nX_Test_CONTROL = []\nY_Test_CONTROL = []\n\nimage_size=224\nimage_size_X=224\nimage_size_Y=224\n\n#0=resize only, 1=CLAHE, 2=denoise, 3=dnoise_after_clahe, 4=old_preprocess\npreprocess_method=2\n\nCLASSES = ['CONTROL', 'AD', 'PD']\nmodel_name_to_save = 'hybrid_efficientnet.h5'\n\nepochs_size = 50\nbatch_size_here = 32","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Plot preprocessed image\nimport cv2\nimport argparse\nimport numpy as np\n\n#This function will plot two images side by side\ndef plot_image(image_1, image_2, title_1=\"Orignal\", title_2=\"Preprocessed\"):\n    \n    print('Original img shape: ' + str(image_1.shape))\n    #print(type(image_1.shape))    \n    print('Processed img shape: ' + str(image_2.shape))\n    #print(type(image_2.shape))\n    \n    #8/8 inch figure\n    width_inch = 8\n    height_inch = 8\n    plt.figure(figsize=(width_inch, height_inch))\n    row = 1\n    column = 2\n    \n    position = 1\n    plt.subplot(row, column, position)\n    plt.imshow(image_1)\n    plt.title(title_1)\n    \n    position = 2\n    plt.subplot(row, column, position)\n    plt.imshow(image_2)\n    plt.title(title_2)\n            \n    #save the image\n    filter_img_name = title_1\n    filter_img_name = SAVE_DIR + filter_img_name.replace(': Original', '')\n    print(filter_img_name)\n    plt.savefig(filter_img_name, dpi=100)\n    \n    #show the image\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Plot preprocessed image\n#This function will plot three images side by side\ndef plot_3_images(image_1, image_2, image_3, img_type):\n    \n    print('Original img shape: ' + str(image_1.shape))\n    #print(type(image_1.shape))    \n    print('Processed img shape: ' + str(image_3.shape))\n    #print(type(image_2.shape))\n    \n    #12/8 inch figure\n    width_inch = 12\n    height_inch = 8\n    plt.figure(figsize=(width_inch, height_inch))\n    row = 1\n    column = 3\n    \n    position = 1\n    plt.subplot(row, column, position)\n    plt.imshow(image_1)\n    plt.title(img_type + \"_Original\")\n    \n    position = 2\n    plt.subplot(row, column, position)\n    plt.imshow(image_2)\n    plt.title(img_type + \"_after CLAHE\")\n            \n    position = 3\n    plt.subplot(row, column, position)\n    plt.imshow(image_3)\n    plt.title(img_type + \"_after Denoise\")\n    \n    #save the image\n    filter_img_name = img_type + \".png\"\n    filter_img_name = SAVE_DIR + filter_img_name\n    print(filter_img_name)\n    plt.savefig(filter_img_name, dpi=100)\n    \n    #show the image\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#funtion for mean filter/blur\ndef resize_only(folderPath, image_name):\n    \n    image = cv2.imread(os.path.join(folderPath, image_name))\n    \n    #preprocessing\n    processed_image = cv2.resize(image, (image_size_X, image_size_Y))  \n    \n    #Images to plot\n    img_list = ['PD_2.png', 'CONTROL_PD_1.png', 'AD_9.png']\n    #print(image_name)\n    if image_name in img_list:\n        print(\"resize_only: \" + folderPath + image_name)\n        plot_image(image, processed_image, title_1 = image_name + \": Original\", title_2 = image_name + \": Processed\") \n        \n    return processed_image\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Preprocessing defination\n#https://www.kaggle.com/code/natigmamishov/complete-guide-to-image-processing-with-opencv\n#funtion for mean filter/blur\ndef preprocess_image(folderPath, image_name):\n    \n    image = cv2.imread(os.path.join(folderPath, image_name))\n    \n    #preprocessing\n    processed_image = cv2.resize(image, (image_size_X, image_size_Y))        \n    processed_image = cv2.cvtColor(np.array(processed_image), cv2.COLOR_RGB2BGR)\n    processed_image = cv2.bilateralFilter(processed_image, 15, 75, 75)\n    \n    # denoising the image using the cv2.fastNlMeansDenoising() function  \n    processed_image = cv2.fastNlMeansDenoising(image, None, 15, 7, 21 )  \n        \n    #image = cv2.imread(img)\n    #processed_image = cv2.blur(image, kernel)    \n    #cv2.filter2D(image,-1,kernel) = cv2.filter2D(image,-1,kernel)\n    #writing_path = PRE_PRO_DIR + target_folder + '/' + image_name;\n    #print(writing_path)\n    #cv2.imwrite(writing_path, processed_image)\n    #plot_image(image, processed_image)\n    \n    #Images to plot\n    img_list = ['PD_2.png', 'CONTROL_PD_1.png', 'AD_9.png']\n    #print(image_name)\n    if image_name in img_list:\n        print(\"preprocess_image: \" + folderPath + image_name)\n        plot_image(image, processed_image, title_1 = image_name + \": Original\", title_2 = image_name + \": Processed\") \n    \n    return processed_image\n    \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#CLAHE Histogram Equalization\n#Contrast Limited Adaptive Histogram Equalization (CLAHE)\n#https://www.geeksforgeeks.org/clahe-histogram-eqalization-opencv/\ndef preprocess_CLAHE(folderPath, image_name):\n    \n    # Open the image as a grayscale image\n    #image = cv2.imread(os.path.join(folderPath, image_name), 0 )\n    \n    # Open the image as original\n    image = cv2.imread(os.path.join(folderPath, image_name))\n    \n    #Convert to grayscale if open as original\n    processed_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    #changes the shape to (X, Y)\n    \n    processed_image = cv2.resize(processed_image, (image_size_X, image_size_Y)) \n    \n    # The initial processing of the image\n    # image = cv2.medianBlur(image, 3)\n    \n    # The declaration of CLAHE\n    # clipLimit -> Threshold for contrast limiting\n    \n    #clahe = cv2.createCLAHE(clipLimit = 5)    \n    #processed_image = clahe.apply(processed_image) + 30\n    \n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n    processed_image = clahe.apply(processed_image)\n    \n    # Convert the image back to RGB\n    #processed_image = cv2.cvtColor(processed_image, cv2.COLOR_RGB2BGR)\n    processed_image = cv2.cvtColor(processed_image, cv2.COLOR_GRAY2BGR)\n    \n    #changes the shape to (150, 150, 3)\n    \n    #Images to plot\n    img_list = ['PD_2.png', 'CONTROL_PD_1.png', 'AD_9.png']\n    #print(image_name)\n    if image_name in img_list:\n        print(\"preprocess_CLAHE: \" + folderPath + image_name)\n        plot_image(image, processed_image, title_1 = image_name + \": Original\", title_2 = image_name + \": Processed\") \n    \n    return processed_image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def image_denoise(folderPath, image_name):\n    \n    # Open the image as a grayscale image\n    #image = cv2.imread(os.path.join(folderPath, image_name), 0 )\n    \n    # Open the image as original\n    image = cv2.imread(os.path.join(folderPath, image_name))\n    #Convert to grayscale\n    processed_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # Record the dimensions of the image\n    #height, width = image.shape\n    \n    # We enlarge the image to the following dimensions: 200 pixels in height\n    # Note that we resize images while maintaining the aspect ratio.\n    processed_image = cv2.resize(processed_image, (image_size_X, image_size_Y))  \n    \n    \n    #processed_image = cv2.fastNlMeansDenoising(processed_image, None, 23, 7 ,21)\n    #makes the image full black\n    #processed_image = cv2.threshold(processed_image, 128, 255, cv2.THRESH_BINARY_INV)[1]\n    \n    processed_image = cv2.fastNlMeansDenoising(processed_image, None, 10, 7, 21)\n    #processed_image = cv2.adaptiveThreshold(processed_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n    \n    #resize to x, y, z\n    processed_image = cv2.cvtColor(processed_image, cv2.COLOR_RGB2BGR)\n    \n    # Perform binarization of the image (covert to black and white)\n    #ret, processed_image = cv2.threshold(processed_image,127,255,cv2.THRESH_BINARY)\n    \n    # Save and replace the old image with the new image\n    #cv2.imwrite( imageName, img)\n    \n    # Now sharpen the image and improve resolution with PIL \n    #im = Image.open( imageName )\n    \n    # Save the image with higher resolution\n    #im.save(imageName, dpi=(600,600))\n    \n    # Wait for image to save\n    #time.sleep(10)\n    \n    #Images to plot\n    img_list = ['PD_2.png', 'CONTROL_PD_1.png', 'AD_9.png']\n    #print(image_name)\n    if image_name in img_list:\n        print(\"image_denoise: \" + folderPath + image_name)\n        plot_image(image, processed_image, title_1 = image_name + \": Original\", title_2 = image_name + \": Processed\") \n    \n    return processed_image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def image_denoise_after_CLAHE(folderPath, image_name, clahe_image):\n    \n    # Open the image as a grayscale image\n    #image = cv2.imread(os.path.join(folderPath, image_name), 0 )\n    \n    # Open the image as original\n    image = cv2.imread(os.path.join(folderPath, image_name))\n    \n    #Convert to grayscale\n    processed_image = cv2.cvtColor(clahe_image, cv2.COLOR_BGR2GRAY)\n\n    # Record the dimensions of the image\n    #height, width = image.shape\n    \n    # We enlarge the image to the following dimensions: 200 pixels in height\n    # Note that we resize images while maintaining the aspect ratio.\n    processed_image = cv2.resize(processed_image, (image_size_X, image_size_Y))  \n    \n    \n    #processed_image = cv2.fastNlMeansDenoising(processed_image, None, 23, 7 ,21)\n    #makes the image full black\n    #processed_image = cv2.threshold(processed_image, 128, 255, cv2.THRESH_BINARY_INV)[1]\n    \n    processed_image = cv2.fastNlMeansDenoising(processed_image, None, 10, 7, 21)\n    #processed_image = cv2.adaptiveThreshold(processed_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n    \n    #resize to x, y, z\n    #processed_image = cv2.cvtColor(processed_image, cv2.COLOR_RGB2BGR)\n    processed_image = cv2.cvtColor(processed_image, cv2.COLOR_GRAY2BGR)\n    \n    # Perform binarization of the image (covert to black and white)\n    #ret, processed_image = cv2.threshold(processed_image,127,255,cv2.THRESH_BINARY)\n    \n    # Save and replace the old image with the new image\n    #cv2.imwrite( imageName, img)\n    \n    # Now sharpen the image and improve resolution with PIL \n    #im = Image.open( imageName )\n    \n    # Save the image with higher resolution\n    #im.save(imageName, dpi=(600,600))\n    \n    # Wait for image to save\n    #time.sleep(10)\n    \n    #Images to plot\n    img_list = ['PD_2.png', 'CONTROL_PD_1.png', 'AD_9.png']\n    #print(image_name)\n    if image_name == 'PD_2.png':\n        print(\"image_denoise_after_CLAHE: \" + folderPath + image_name)\n        plot_3_images(image, clahe_image, processed_image, \"PD\") \n    elif image_name == 'CONTROL_PD_1.png':\n        plot_3_images(image, clahe_image, processed_image, \"CONTROL\") \n    elif image_name == 'AD_9.png':\n        plot_3_images(image, clahe_image, processed_image, \"AD\") \n    \n    return processed_image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Image preprocessed and appended with Label to list\nprint('preprocess method: ' + str(preprocess_method))\nfor label in labels:\n    folderPath = os.path.join(BASE_DIR, 'train', label)\n    for img_name in tqdm(os.listdir(folderPath)):\n        #image = cv2.imread(os.path.join(folderPath, j))\n        #image = cv2.resize(image, (image_size_X, image_size_Y))        \n        #images = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n        #image = cv2.bilateralFilter(image, 15, 75, 75)\n        \n        #preprocessing\n        #without preprocessing\n        if preprocess_method == 0:\n            image = resize_only(folderPath, img_name)\n        \n        #CLAHE on original image\n        elif preprocess_method == 1:        \n            image = preprocess_CLAHE(folderPath, img_name)\n        \n        #denoise on original image\n        elif preprocess_method == 2:        \n            image = image_denoise(folderPath, img_name)\n            \n        #denoise after CLAHE\n        elif preprocess_method == 3:        \n            image = preprocess_CLAHE(folderPath, img_name)\n            image = image_denoise_after_CLAHE(folderPath, img_name, image)\n        \n        #without preprocessing\n        elif preprocess_method == 4:\n            image = preprocess_image(folderPath, img_name)\n        \n        X_train_img.append(image)\n        Y_train_img.append(label)\n        \nfor label in labels:\n    # Join two or more pathname components\n    folderPath = os.path.join(BASE_DIR, 'test', label) \n    for img_name in tqdm(os.listdir(folderPath)):\n        #image = cv2.imread(os.path.join(folderPath, j))\n        #image = cv2.resize(image, (image_size_X, image_size_Y))        \n        #images = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n        #image = cv2.bilateralFilter(image, 15, 75, 75)\n        \n        #preprocessing\n        #without preprocessing\n        if preprocess_method == 0:\n            image = resize_only(folderPath, img_name)\n        \n        #CLAHE on original image\n        elif preprocess_method == 1:        \n            image = preprocess_CLAHE(folderPath, img_name)\n        \n        #denoise on original image\n        elif preprocess_method == 2:        \n            image = image_denoise(folderPath, img_name)\n            \n        #denoise after CLAHE\n        elif preprocess_method == 3:        \n            image = preprocess_CLAHE(folderPath, img_name)\n            image = image_denoise_after_CLAHE(folderPath, img_name, image)\n        \n        #without preprocessing\n        elif preprocess_method == 4:\n            image = preprocess_image(folderPath, img_name)\n        \n        X_train_img.append(image)\n        Y_train_img.append(label)\n        \n        if label == 'AD':\n            X_Test_AD.append(image)\n            Y_Test_AD.append(label)\n        elif label == 'PD':\n            X_Test_PD.append(image)\n            Y_Test_PD.append(label)\n        elif label == 'CONTROL':\n            X_Test_CONTROL.append(image)\n            Y_Test_CONTROL.append(label)\n        \n        \nprint(\"Image loaded.\")\n        \n#converted generated list into array\nX_train = np.array(X_train_img)\nY_train = np.array(Y_train_img)\n\nprint(\"List to array conversion done\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(X_train.shape)\nX_train, Y_train = shuffle(X_train, Y_train, random_state=42)\n\n#After shuffling sample size remains same\nprint(X_train.shape)\nX_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Converting String Label to categorical\ny_train_new = []\ny_test_new = []\n\nfor i in Y_train: \n    #Converting String Label to integer i.e # CONTROL ---> 0, AD---> 1, PD ---> 2\n    y_train_new.append(labels.index(i))\n\n#Converts a class vector (integers) to binary class matrix\nY_train = to_categorical(y_train_new) \n\nfor i in Y_test:\n    y_test_new.append(labels.index(i))\n\nY_test = to_categorical(y_test_new)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#check y train\nY_train","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#save the model\ndef save_model(p_Model, modelName):    \n    with open(SAVE_DIR + modelName + '.h5','a') as f:\n        print(p_Model, file=f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(str(datetime.now()))\ndef get_model_bfr_regularization(model_name):\n    # Initiate EfficientNetB0 model\n    efficientnet_B0 = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(image_size_X, image_size_Y, 3))\n    print(\"If download not started, means already downloaded\")\n    \n    \"\"\"\n    for layer in efficientnet_B0.layers:\n        layer.trainable = False\n    \"\"\"\n    \n    # Output layer of the model\n    model = efficientnet_B0.output\n    \n    model = tf.keras.layers.GlobalAveragePooling2D()(model)\n    model = tf.keras.layers.Dropout(0.5)(model)    \n    model = tf.keras.layers.Dense(3, activation='softmax')(model)\n\n    #Merge input and Output of model\n    model = tf.keras.models.Model(inputs=efficientnet_B0.input, outputs=model)\n\n    #model.name = 'model_summary'\n    \n    #model.summary(print_fn=save_model(model, model_name))\n    #model.summary()\n    \n    print(\"Model is ready\")\n    \n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#efficientnetB0 with augmentation and tuning defination\n\nimg_augmentation = Sequential(\n    [\n        layers.RandomRotation(factor=0.15),\n        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n        layers.RandomFlip(),\n        layers.RandomContrast(factor=0.1),\n    ],\n    name=\"img_augmentation\",\n)\n\nprint(str(datetime.now()))\ndef get_model_aftr_augmentation(model_name):\n    # Initiate EfficientNetB0 model\n    inputs = layers.Input(shape=(image_size_X, image_size_Y, 3))\n    x = img_augmentation(inputs)\n    efficientnet_B0 = EfficientNetB0(include_top=False, input_tensor=x, weights='imagenet')\n    print(\"If download not started, means already downloaded\")\n    \n    \"\"\"\n    for layer in efficientnet_B0.layers:\n        layer.trainable = False\n    \"\"\"\n    \n    # Output layer of the model\n    model = efficientnet_B0.output\n    \n    model = tf.keras.layers.GlobalAveragePooling2D()(model)\n    model = tf.keras.layers.Dropout(0.5)(model)    \n    model = tf.keras.layers.Dense(3, activation='softmax')(model)\n\n    #Merge input and Output of model\n    model = tf.keras.models.Model(inputs=efficientnet_B0.input, outputs=model)\n\n    #model.name = 'model_summary'\n    \n    model.summary(print_fn=save_model(model, model_name))\n    #model.summary()\n    \n    print(\"Model is ready\")\n    \n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.layers import Dense, Input, Activation, add, Add, Dropout, BatchNormalization, GlobalAveragePooling2D\nfrom keras.models import Sequential, Model\n\ndef get_model_aftr_aug_tuning(model_name):\n    \n    print(\"get_model_aftr_aug_tuning\")\n    # Initiate EfficientNetB0 model\n    inputs = layers.Input(shape=(image_size_X, image_size_Y, 3))\n    x = img_augmentation(inputs)\n    model_ENB0 = EfficientNetB0(include_top=False, input_tensor=x, weights='imagenet')\n    print(\"If download not started, means already downloaded\")\n    \n    #model_ENB0 = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(image_size_X ,image_size_X, 3))\n    model_ENB0.trainable = False\n    #model_ENB0.summary()\n    \n    model = Sequential()\n    model.add(model_ENB0)\n    \n    model.summary()\n    \n    # Unfreezing\n    model_ENB0.trainable = True\n    set_trainable = False\n\n    for layer in model_ENB0.layers:\n        if layer.name == 'block6d_se_excite':\n            set_trainable = True\n        if set_trainable:\n            if not isinstance(layer, BatchNormalization):\n                layer.trainable = True\n            else:\n                layer.trainable = False\n        else:\n            layer.trainable = False\n            \n    model.add(GlobalAveragePooling2D())\n    model.add(Dropout(0.5))\n    model.add(Dense(3,activation=\"softmax\"))\n    model.summary()\n    \n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(str(datetime.now()))\ndef get_model_after_layering(model_name):\n    # Initiate EfficientNetB0 model\n    efficientnet_B0 = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(image_size_X, image_size_Y, 3))\n    print(\"If download not started, means already downloaded\")\n    \n    \"\"\"\n    for layer in efficientnet_B0.layers:\n        layer.trainable = False\n    \"\"\"\n    \n    # Output layer of the model\n    model = efficientnet_B0.output\n    \n    \n    model = tf.keras.layers.GlobalAveragePooling2D()(model)\n    model = tf.keras.layers.BatchNormalization()(model)\n    model = tf.keras.layers.Dropout(0.25)(model)\n    model = tf.keras.layers.Dense(256, activation='relu')(model)\n    model = tf.keras.layers.Dropout(0.25)(model)\n    model = tf.keras.layers.Dense(32, activation='relu')(model)\n    model = tf.keras.layers.Dropout(0.25)(model)\n    model = tf.keras.layers.Dense(3, activation='softmax')(model)\n\n    #Merge input and Output of model\n    model = tf.keras.models.Model(inputs=efficientnet_B0.input, outputs=model)\n\n    #model.name = 'model_summary'\n    \n    #model.summary(print_fn=save_model(model, model_name))\n    #model.summary()\n    \n    print(\"Model is ready\")\n    \n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(str(datetime.now()))\ndef get_model_after_layering2(model_name):\n    # Initiate EfficientNetB0 model\n    efficientnet_B0 = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(image_size_X, image_size_Y, 3))\n    print(\"If download not started, means already downloaded\")\n\n    # Output layer of the model\n    #base_model = efficientnet_B0.output\n    \n    model= Sequential()\n    model.add(efficientnet_B0) \n    model.add(tf.keras.layers.Flatten()) \n\n    #Model summary\n    model.summary()\n    \n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.Dense(1024,activation=('relu'),input_dim=512))\n\n    model.add(tf.keras.layers.Dense(512,activation=('relu'))) \n    model.add(tf.keras.layers.Dense(256,activation=('relu'))) \n    model.add(tf.keras.layers.Dropout(.1))\n    model.add(tf.keras.layers.Dense(128,activation=('relu')))\n    model.add(tf.keras.layers.Dropout(.1))\n    model.add(tf.keras.layers.Dense(64,activation=('relu')))\n    model.add(tf.keras.layers.Dropout(.1))\n    model.add(tf.keras.layers.Dense(3,activation=('softmax'))) \n\n    #Checking the final model summary\n    model.summary()\n\n    #Merge input and Output of model\n    #model = tf.keras.models.Model(inputs=efficientnet_B0.input, outputs=model)\n\n    #model.name = 'model_summary'\n    \n    #model.summary(print_fn=save_model(model, model_name))\n    #model.summary()\n    \n    print(\"Model is ready\")\n    \n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(str(datetime.now()))\ndef get_model_after_layering3(model_name):\n    print('get_model_after_layering3')\n    # Initiate EfficientNetB0 model\n    efficientnet_B0 = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(image_size_X, image_size_Y, 3))\n    print(\"If download not started, means already downloaded\")\n\n    # Output layer of the model\n    #base_model = efficientnet_B0.output\n    \n    model=Sequential()\n    chanDim=-1\n    model.add(efficientnet_B0)\n    model.add(GlobalAveragePooling2D())\n    #model.add(Dense(1024,activation=('relu')))\n    model.add(BatchNormalization(axis=chanDim))\n    model.add(Dropout(0.5))\n    model.add(Dense(512,activation=('relu')))\n    model.add(BatchNormalization(axis=chanDim))\n    model.add(Dropout(0.4))\n    model.add(Dense(256,activation=('relu')))\n    model.add(BatchNormalization(axis=chanDim))\n    model.add(Dropout(0.3))\n    model.add(Dense(128,activation=('relu')))\n    model.add(BatchNormalization(axis=chanDim))\n    model.add(Dropout(0.2))\n    model.add(Dense(3,activation=('softmax')))\n    \n    #Checking the final model summary\n    model.summary()\n\n    #Merge input and Output of model\n    #model = tf.keras.models.Model(inputs=efficientnet_B0.input, outputs=model)\n\n    #model.name = 'model_summary'\n    \n    #model.summary(print_fn=save_model(model, model_name))\n    #model.summary()\n    \n    print(\"Model is ready\")\n    \n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#efficientnetB7 with augmentation and tuning defination\n#from tensorflow.keras.models import Sequential\n#from tensorflow.keras import layers\n\nimg_augmentation = Sequential(\n    [\n        layers.RandomRotation(factor=0.15),\n        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n        layers.RandomFlip(),\n        layers.RandomContrast(factor=0.1),\n    ],\n    name=\"img_augmentation\",\n)\n\nprint(str(datetime.now()))\ndef get_model_efficientnetB7(model_name):\n    # Initiate EfficientNetB0 model\n    inputs = layers.Input(shape=(image_size_X, image_size_Y, 3))\n    x = img_augmentation(inputs)\n    efficientnet_B7 = EfficientNetB7(include_top=False, input_tensor=x, weights='imagenet')\n    print(\"If download not started, means already downloaded\")\n    \n    \"\"\"\n    for layer in efficientnet_B0.layers:\n        layer.trainable = False\n    \"\"\"\n    \n    # Output layer of the model\n    model = efficientnet_B7.output\n    \n    model = tf.keras.layers.GlobalAveragePooling2D()(model)\n    model = tf.keras.layers.Dropout(0.2)(model)    \n    model = tf.keras.layers.Dense(3, activation='softmax')(model)\n\n    #Merge input and Output of model\n    model = tf.keras.models.Model(inputs=efficientnet_B7.input, outputs=model)\n\n    #model.name = 'model_summary'\n    \n    model.summary(print_fn=save_model(model, model_name))\n    #model.summary()\n    \n    print(\"Model is ready\")\n    \n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(str(datetime.now()))\ndef get_model_aftr_regularization(model_name):\n    # Initiate EfficientNetB0 model\n    efficientnet_B0 = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(image_size_X, image_size_Y, 3))\n    print(\"If download not started, means already downloaded\")\n\n    # Output layer of the model\n    model = efficientnet_B0.output\n    \n    model = tf.keras.layers.GlobalAveragePooling2D()(model)\n    model = tf.keras.layers.Dropout(0.5)(model)    \n    model = tf.keras.layers.Dense(64, kernel_regularizer=regularizers.l2(0.01), activation='softmax')(model)\n    model = tf.keras.layers.Dense(3, activation='softmax')(model)\n\n    #Merge input and Output of model\n    model = tf.keras.models.Model(inputs=efficientnet_B0.input, outputs=model)\n    \n    #model.summary(print_fn=save_model(model, model_name))\n    #model.summary()\n    \n    print(\"Model is ready\")\n    \n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_model_aftr_tuning(model_name):\n    model_ENB0 = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(image_size_X ,image_size_X, 3))\n    model_ENB0.trainable = False\n    model_ENB0.summary()\n    \n    model = Sequential()\n    model.add(model_ENB0)\n    \n    \n    # Unfreezing\n    model_ENB0.trainable = True\n    set_trainable = False\n\n    for layer in model_ENB0.layers:\n        if layer.name == 'block6d_se_excite':\n            set_trainable = True\n        if set_trainable:\n            if not isinstance(layer, BatchNormalization):\n                layer.trainable = True\n            else:\n                layer.trainable = False\n        else:\n            layer.trainable = False\n            \n    model.add(GlobalAveragePooling2D())\n    model.add(Dropout(0.5))\n    model.add(Dense(3,activation=\"softmax\"))\n    #model.summary()\n    \n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_model_VGG19(model_name):\n    base_model_VGG19 = tf.keras.applications.VGG19(input_shape=(image_size_X, image_size_Y,3),\n                                               include_top=False,\n                                               weights = \"imagenet\"\n                                            )\n    base_model_VGG19.trainable = False\n    \n    model_vgg = tf.keras.Sequential\n    ([\n        base_model_VGG19,\n        tf.keras.layers.MaxPooling2D(),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(2, activation=\"softmax\")\n    ])\n    \n    model_vgg.summary()\n    return model_vgg","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(str(datetime.now()))\n#mesurments metrix for the training of the model\nMETRICS = [tf.keras.metrics.CategoricalAccuracy(name='acc'),\n           tf.keras.metrics.AUC(name='auc')]\n\n#custom_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\ncustom_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n\nprint(custom_optimizer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(str(datetime.now()))\n\n#tensorBoard = TensorBoard(log_dir = SAVE_DIR + \"logs\")\ntensorBoard = TensorBoard(log_dir = SAVE_DIR)\n\nreduce_lr = ReduceLROnPlateau(\n    #monitor='val_loss',\n    monitor='val_acc',\n    factor=0.3,\n    patience=5,\n    verbose=1,\n    mode='auto',\n    min_delta=0.001\n)\n\n#patience = epochs_size means no early stopping\nes = EarlyStopping(\n    #monitor='val_loss',\n    monitor='val_acc',\n    patience=epochs_size,\n    verbose=1,\n    mode='auto',\n    restore_best_weights=True\n) \n\n\ndef define_checkPoint(model_name):\n        \n    checkPoint = ModelCheckpoint(\n        SAVE_DIR + model_name + '.tf',\n        #monitor='val_loss',\n        monitor='val_acc',\n        verbose=1,\n        save_best_only=True,\n        mode='auto'\n    )\n    \n    return checkPoint\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\n\nprint(str(datetime.now()))\ndef print_output(model, history, model_name):\n    \n    #save the model\n    #filename = \"completed_model.joblib\"\n    #joblib.dump(model, SAVE_DIR + filename)\n    \n    trend_of_the_metrics = model_name + '_' + 'trend_of_the_metrics.png'\n    Accuracy_vs_Loss_of_Training = model_name + '_' + 'Accuracy_vs_Loss_of_Training.png'\n    Training_vs_Validation_Accuracy = model_name + '_' + 'Training_vs_Validation_Accuracy.png'\n    Training_vs_Validation_Loss = model_name + '_' + 'Training_vs_Validation_Loss.png'\n    classification_report_name = model_name + '_' + 'classification_report.txt'\n    confusion_matrix_name = model_name + '_' + 'confusion_matrix.png'\n    model_name_to_save = model_name + '.tf'\n        \n    print('Plotting the trend of the metrics during training by the model')\n    fig, ax = plt.subplots(1, 3, figsize = (60, 10))\n    ax = ax.ravel()\n\n    for i, metric in enumerate([\"acc\", \"auc\", \"loss\"]):\n        print(i)\n        print (metric)\n        ax[i].plot(history.history[metric])\n        ax[i].plot(history.history[\"val_\" + metric])\n        ax[i].set_title(\"Model {}\".format(metric))\n        ax[i].set_xlabel(\"Epochs\")\n        ax[i].set_ylabel(metric)\n        ax[i].legend([\"train\", \"val\"])\n\n    #save plot\n    plt.savefig(SAVE_DIR + trend_of_the_metrics, bbox_inches = 'tight')\n    \n    \n    print('Plotting training, validation and loss curve')\n    get_ac = history.history['acc']\n    get_los = history.history['loss']\n    val_acc = history.history['val_acc']\n    val_loss = history.history['val_loss']\n\n    epochs = range(len(get_ac))\n\n    #Accuracy vs Loss of Training\n    plt.plot(epochs, get_ac, 'g', label='Training Accuracy')\n    plt.plot(epochs, get_los, 'r', label='Training Loss')\n    plt.title('Accuracy vs Loss of Training')\n    plt.xlabel('No of Epochs')\n    plt.ylabel('Accuracy/Loss of Training')\n    plt.legend(loc=0)\n    plt.savefig(SAVE_DIR + Accuracy_vs_Loss_of_Training, bbox_inches = 'tight')\n    plt.figure()\n\n\n    #Figure Training vs Validation Accuracy\n    plt.plot(epochs, get_ac, 'g', label='Training Data Accuracy')\n    plt.plot(epochs, val_acc, 'r', label='Validation Data Accuracy')\n    plt.title('Training vs Validation Accuracy of the proposed model')\n    plt.xlabel('No of Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(loc=0)\n\n    plt.savefig(SAVE_DIR + Training_vs_Validation_Accuracy, bbox_inches = 'tight')\n    plt.figure()\n\n\n\n    #Figure Training vs Validation Loss\n    plt.plot(epochs, get_los, 'g', label='Training Loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n    plt.title('Training vs Validation Loss of the proposed model')\n    plt.xlabel('No of Epochs')\n    plt.ylabel('Loss')\n    plt.legend(loc=0)\n    plt.savefig(SAVE_DIR + Training_vs_Validation_Loss, bbox_inches = 'tight')\n    plt.figure()\n    plt.show()\n    \n    \n    print('classification_report report of training and validation')\n    pred = model.predict(X_test)\n    pred_labels = np.argmax(pred, axis=1)\n    actual_label = np.argmax(Y_test, axis=1)\n    \n    #print(classification_report(actual_label, pred_labels, target_names=labels))\n    report = classification_report(actual_label, pred_labels, target_names=labels)\n    print(report)\n    report_path = classification_report_name\n    text_file = open(report_path, \"w\")\n    n = text_file.write(report)\n    text_file.close()\n    \n        \n    \n    print('Preparing Confusion matrix')\n    cnf = confusion_matrix(actual_label, pred_labels)\n    plt.figure(figsize=(8,6), dpi=70, facecolor='w', edgecolor='k')\n    ax = sns.heatmap(cnf, cmap='Blues',annot=True, fmt='d', xticklabels=labels, yticklabels=labels)\n    plt.title('Alzheimer\\'s and Parkinson\\'s Classification')\n    plt.xlabel('Prediction')\n    plt.ylabel('Ground Truth')\n\n    #save plot\n    plt.savefig(SAVE_DIR + confusion_matrix_name, bbox_inches = 'tight')\n    plt.show(ax)\n    \n    \n    #Load save the model for further use\n    #saved_model = tf.keras.models.load_model(SAVE_DIR + model_name_to_save)\n\n    #Show Model Architecture\n    #plot_model(saved_model, to_file='efficient_net_B0.png', show_shapes=True, show_layer_names=True)\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n#Model efficientnetb0\ndef model_efficientnetb0(model_type):\n    print(str(datetime.now()))\n    model_name = 'b0-CNN' + '-' + str(model_type)\n    #Configures the model for training\n    #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n    \n    #B0-CNN\n    if model_type == 1:\n        model = get_model_bfr_regularization(model_name)\n        \n    elif model_type == 2:\n        model = get_model_aftr_regularization(model_name)\n    \n    elif model_type == 3:\n        model = get_model_aftr_augmentation(model_name)\n        \n    elif model_type == 4:\n        model = get_model_aftr_tuning(model_name)\n    \n    #73%\n    elif model_type == 5:\n        model = get_model_aftr_aug_tuning(model_name)\n        \n    elif model_type == 6:\n        model = get_model_after_layering(model_name)\n        \n    elif model_type == 7:\n        model = get_model_after_layering2(model_name)\n        \n    elif model_type == 8:\n        model = get_model_after_layering3(model_name)\n        \n    elif model_type == 50:\n        model = get_model_efficientnetB7(model_name) \n        \n    else:\n        model = get_model_aftr_tuning(model_name)\n        \n    #model.summary(print_fn=save_model(model, model_name))\n    model.summary()\n    model.compile(optimizer=custom_optimizer, loss=tf.losses.CategoricalCrossentropy(), metrics=METRICS)\n\n    # Create an instance of ImageDataGenerator for data augmentation\n    datagen = ImageDataGenerator(\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\n\n    # Fit the data generator to your data\n    #datagen.fit(X_train)\n    \n    from sklearn.model_selection import train_test_split\n\n    print(\"Data size before splitting (without test data)\")\n    print(X_train.shape, Y_train.shape)\n    \n    # Split the data into a training set and a validation set\n    X_train_f, X_val, Y_train_f, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\n    \n    print(\"Training data shape\")\n    print(X_train_f.shape, Y_train_f.shape)\n\n    print(\"Test data shape\")\n    print(X_test.shape, Y_test.shape)\n\n    print(\"Validation data shape\")\n    print(X_val.shape, Y_val.shape)\n    \n    #train\n    print(str(datetime.now()))\n    checkPoint = define_checkPoint(model_name)\n    \n    if with_augmentation == 1:\n        print('Fit the model with data augmentation')\n        \n        augmented_dataset = datagen.flow(X_train_f, Y_train_f, batch_size=32)\n        print('Training Data size after augmentation')\n        \n        # Get the shape of augmented dataset\n        #shows error \"AttributeError: 'tuple' object has no attribute 'shape'\"\n        #print(\"Shape of x_augmented:\", augmented_dataset[0].shape)\n        #print(\"Shape of y_augmented:\", augmented_dataset[1].shape)  \n        \n        #print augmented image\n        #print_augmented_images()\n\n        history = model.fit(\n                    augmented_dataset,\n                    batch_size=batch_size_here,\n                    #validation_split=0.1,\n                    #validation_data=datagen.flow(X_val, Y_val, batch_size=32),\n                    validation_data=(X_val, Y_val),\n                    epochs=epochs_size,\n                    verbose=1,\n                    callbacks=[tensorBoard, checkPoint, reduce_lr, es]\n                )\n    else:\n        print('Fit the model without data augmentation')\n        history = model.fit(X_train_f, Y_train_f,\n                    batch_size=batch_size_here,\n                    #validation_split=0.1,\n                    validation_data=(X_val, Y_val),\n                    epochs=epochs_size,\n                    verbose=1,\n                    callbacks=[tensorBoard, checkPoint, reduce_lr, es]\n                )\n        \n\n\n    #Evaluating the hybrid model on training, test and validation data\n\n    #train_scores = hybrid_model.evaluate(train_data, train_labels)\n    #val_scores = hybrid_model.evaluate(val_data, val_labels)\n    test_scores = model.evaluate(X_test, Y_test)\n\n    #print(\"Training Accuracy of the model: %.2f%%\"%(train_scores[1] * 100))\n    #print(\"Validation Accuracy of the model: %.2f%%\"%(val_scores[1] * 100))\n    print(model_name + \": Testing Accuracy of the model: %.2f%%\"%(test_scores[1] * 100))\n\n\n    #Print final output\n    print_output(model, history, model_name)\n    \n    # Display predicted Images\n    #predict_mri(X_test, Y_test)  \n    \n    \"\"\"\n    try:\n        # Save the model in the .pb format\n        tf.saved_model.save(model, 'my_model')\n    except Exception as e:\n        print(\"An error occurred:\", e)\n    finally:\n        print(\"Model save Done.\")\n    \"\"\"\n    \n    return history","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#print augmented images\ndef print_augmented_images():\n    # Load image and apply data augmentation\n    #image = Image.open('/kaggle/input/working-ds/AD_PD_DETECTION/ORIGINAL_AD_PD_DATA/test/AD/AD_2562.png')\n    image = image_denoise('/kaggle/input/working-ds/AD_PD_DETECTION/ORIGINAL_AD_PD_DATA/test/AD/', 'AD_2562.png')\n    \n    image_array = np.array(image)\n    image_array = np.expand_dims(image_array, axis=0)\n    \n    dg = ImageDataGenerator(\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\n    aug_iter = dg.flow(image_array, batch_size=32)\n\n    # Show augmented images\n    fig, axs = plt.subplots(nrows=4, ncols=4, figsize=(16,16))\n    for i in range(4):\n        for j in range(4):\n            axs[i][j].imshow(next(aug_iter)[0].astype(np.uint8))\n            axs[i][j].axis('off')\n    \n    plt.savefig(SAVE_DIR + 'augmented_images.png', bbox_inches = 'tight')\n    plt.show()\n    \n\ntry:\n    print_augmented_images()\nexcept Exception as e:\n    print(\"An error occurred:\", e)\nfinally:\n    print(\"Augmented image printing Done.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Not working\nfrom skimage import io\n#print augmented images\ndef print_augmented_images2():\n    # Load image and apply data augmentation\n    #image = Image.open('/kaggle/input/working-ds/AD_PD_DETECTION/ORIGINAL_AD_PD_DATA/test/AD/AD_2562.png')\n    #image = image_denoise('/kaggle/input/working-ds/AD_PD_DETECTION/ORIGINAL_AD_PD_DATA/test/AD/', 'AD_2562.png')\n    \n    # Load the image\n    img_path = '/kaggle/input/working-ds/AD_PD_DETECTION/ORIGINAL_AD_PD_DATA/test/AD/AD_2562.png'\n    img = io.imread(img_path)\n\n    # Reshape the image to (1, height, width, channels) for use with ImageDataGenerator\n    img = img.reshape((1,) + img.shape)\n\n    # Create an instance of the ImageDataGenerator class with your set of augmentation options\n    data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n            rotation_range=40,\n            width_shift_range=0.2,\n            height_shift_range=0.2,\n            shear_range=0.2,\n            zoom_range=0.2,\n            horizontal_flip=True,\n            fill_mode='nearest'\n    )\n\n    # Apply the augmentation to the image\n    batch_size = 1\n    img_generator = data_gen.flow(img, batch_size=batch_size)\n    aug_imgs, _ = next(img_generator)\n\n    # Plot the augmented image\n    fig, ax = plt.subplots(figsize=(5, 5))\n    ax.imshow(aug_imgs[0].astype('uint8'))\n    plt.show()\n    \n\"\"\"\ntry:\n    print_augmented_images2()\nexcept Exception as e:\n    print(\"An error occurred:\", e)\nfinally:\n    print(\"Printing Done.\")\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#model VGG19\ndef model_VGG19_notworking():\n    print(str(datetime.now()))\n    model_name = 'hybrid_VGG19'\n    #Configures the model for training\n    #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n    #model = get_model_bfr_regularization()\n    #model = get_model_VGG19(model_name)\n\n    base_model_VGG19 = tf.keras.applications.VGG19(input_shape=(image_size_X, image_size_Y,3),\n                                                   include_top=False,\n                                                   weights = \"imagenet\"\n                                                )\n    base_model_VGG19.trainable = False\n\n    model = tf.keras.Sequential\n    ([\n        base_model_VGG19,\n        tf.keras.layers.MaxPooling2D(),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(3, activation=\"softmax\")\n    ])\n\n    #model.summary(print_fn=save_model(model, model_name))\n    #model.summary()\n    with open(SAVE_DIR + model_name + '.h5','a') as f:\n        print(model, file=f)\n\n    model.compile(optimizer=custom_optimizer, loss=tf.losses.CategoricalCrossentropy(), metrics=METRICS)\n    #model.compile(loss='categorical_crossentropy' , optimizer=tf.keras.optimizers.Adam(lr = 0.001) , metrics='accuracy')\n\n    #train\n    print(str(datetime.now()))\n    checkPoint = define_checkPoint(model_name)\n    history = model.fit(X_train, \n                        Y_train,\n                        batch_size=batch_size_here,\n                        validation_split=0.1,\n                        epochs=epochs_size,\n                        verbose=1,\n                        callbacks=[tensorBoard, checkPoint, reduce_lr, es]\n                       )\n\n    #Evaluating the hybrid model on test data\n    test_scores = model.evaluate(X_test, Y_test)\n    print(model_name + \": Testing Accuracy of the model: %.2f%%\"%(test_scores[1] * 100))\n\n    #Print final output\n    print_output(model, history, model_name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#VGG16\ndef model_VGG16():\n    print(str(datetime.now()))\n    model_name = 'hybrid_VGG16'\n    conv_model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n\n    for layer in conv_model.layers:\n        layer.trainable = False\n\n    # flatten the output of the convolutional part: \n    x = tf.keras.layers.Flatten()(conv_model.output)\n    # three hidden layers\n    x = tf.keras.layers.Dense(100, activation='relu')(x)\n    x = tf.keras.layers.Dense(100, activation='relu')(x)\n    x = tf.keras.layers.Dense(100, activation='relu')(x)\n    # final softmax layer with three categories \n    predictions = tf.keras.layers.Dense(3, activation='softmax')(x)\n\n    # creating the full model:\n    model = tf.keras.models.Model(inputs=conv_model.input, outputs=predictions)\n    #model.summary()\n    with open(SAVE_DIR + model_name + '.h5','a') as f:\n        print(model, file=f)\n\n    model.compile(optimizer=custom_optimizer, loss=tf.losses.CategoricalCrossentropy(), metrics=METRICS)\n    #model.compile(loss='categorical_crossentropy' , optimizer=tf.keras.optimizers.Adam(lr = 0.001) , metrics='accuracy')\n\n    #train\n    print(str(datetime.now()))\n    checkPoint = define_checkPoint(model_name)\n    history = model.fit(X_train, \n                        Y_train,\n                        batch_size=batch_size_here,\n                        validation_split=0.1,\n                        epochs=epochs_size,\n                        verbose=1,\n                        callbacks=[tensorBoard, checkPoint, reduce_lr, es]\n                       )\n\n    #Evaluating the hybrid model on test data\n    test_scores = model.evaluate(X_test, Y_test)\n    print(model_name + \": Testing Accuracy of the model: %.2f%%\"%(test_scores[1] * 100))\n\n    #Print final output\n    print_output(model, history, model_name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#VGG19\ndef model_VGG19():\n    print(str(datetime.now()))\n    model_name = 'hybrid_VGG19'\n    vgg19 = tf.keras.applications.vgg19\n\n    conv_model = vgg19.VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3))\n    for layer in conv_model.layers: \n        layer.trainable = False\n\n    x = tf.keras.layers.Flatten()(conv_model.output)\n    x = tf.keras.layers.Dense(100, activation='relu')(x)\n    x = tf.keras.layers.Dense(100, activation='relu')(x)\n    x = tf.keras.layers.Dense(100, activation='relu')(x)\n    predictions = tf.keras.layers.Dense(3, activation='softmax')(x)\n    model = tf.keras.models.Model(inputs=conv_model.input, outputs=predictions)\n    model.summary()\n\n    with open(SAVE_DIR + model_name + '.h5','a') as f:\n        print(model, file=f)\n\n    model.compile(optimizer=custom_optimizer, loss=tf.losses.CategoricalCrossentropy(), metrics=METRICS)\n    #model.compile(loss='categorical_crossentropy' , optimizer=tf.keras.optimizers.Adam(lr = 0.001) , metrics='accuracy')\n\n    #train\n    print(str(datetime.now()))\n    checkPoint = define_checkPoint(model_name)\n    history = model.fit(X_train, \n                        Y_train,\n                        batch_size=batch_size_here,\n                        validation_split=0.1,\n                        epochs=epochs_size,\n                        verbose=1,\n                        callbacks=[tensorBoard, checkPoint, reduce_lr, es]\n                       )\n\n    #Evaluating the hybrid model on test data\n    test_scores = model.evaluate(X_test, Y_test)\n    print(model_name + \": Testing Accuracy of the model: %.2f%%\"%(test_scores[1] * 100))\n\n    #Print final output\n    print_output(model, history, model_name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#ResNet50\ndef model_ResNet50():\n    print(str(datetime.now()))\n    model_name = 'hybrid_ResNet50'\n    resnet50 = tf.keras.applications.resnet50\n\n    conv_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n    \n    for layer in conv_model.layers:\n        layer.trainable = False\n    \n    x = tf.keras.layers.Flatten()(conv_model.output)\n    x = tf.keras.layers.Dense(100, activation='relu')(x)\n    x = tf.keras.layers.Dense(100, activation='relu')(x)\n    x = tf.keras.layers.Dense(100, activation='relu')(x)\n    predictions = tf.keras.layers.Dense(3, activation='softmax')(x)\n    model = tf.keras.models.Model(inputs=conv_model.input, outputs=predictions)\n    model.summary()\n\n    with open(SAVE_DIR + model_name + '.h5','a') as f:\n        print(model, file=f)\n\n    model.compile(optimizer=custom_optimizer, loss=tf.losses.CategoricalCrossentropy(), metrics=METRICS)\n    #model.compile(loss='categorical_crossentropy' , optimizer=tf.keras.optimizers.Adam(lr = 0.001) , metrics='accuracy')\n\n    #train\n    print(str(datetime.now()))\n    checkPoint = define_checkPoint(model_name)\n    history = model.fit(X_train, \n                        Y_train,\n                        batch_size=batch_size_here,\n                        validation_split=0.1,\n                        epochs=epochs_size,\n                        verbose=1,\n                        callbacks=[tensorBoard, checkPoint, reduce_lr, es]\n                       )\n\n    #Evaluating the hybrid model on test data\n    test_scores = model.evaluate(X_test, Y_test)\n    print(model_name + \": Testing Accuracy of the model: %.2f%%\"%(test_scores[1] * 100))\n\n    #Print final output\n    print_output(model, history, model_name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#efficientnetB0 with augmentation and tuning defination\n#from tensorflow.keras.models import Sequential\n#from tensorflow.keras import layers\n\nimg_augmentation = Sequential(\n    [\n        layers.RandomRotation(factor=0.15),\n        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n        layers.RandomFlip(),\n        layers.RandomContrast(factor=0.1),\n    ],\n    name=\"img_augmentation\",\n)\n\ndef get_EfficientNetB0_with_aug(model_name):\n    inputs = layers.Input(shape=(image_size_X, image_size_Y, 3))\n    x = img_augmentation(inputs)\n    model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n\n    # Freeze the pretrained weights\n    #model.trainable = False\n\n    # Rebuild top\n    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n    x = layers.BatchNormalization()(x)\n\n    top_dropout_rate = 0.2\n    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n    outputs = layers.Dense(3, activation=\"softmax\", name=\"pred\")(x)\n\n    # Compile\n    model = tf.keras.Model(inputs, outputs, name=model_name)\n    with open(SAVE_DIR + model_name + '.h5','a') as f:\n        print(model, file=f)\n    \n    model.compile(optimizer=custom_optimizer, loss=tf.losses.CategoricalCrossentropy(), metrics=METRICS)\n    \n    return model\n\ndef get_EfficientNetB0_with_aug_tune(model_name):\n    inputs = layers.Input(shape=(image_size_X, image_size_Y, 3))\n    x = img_augmentation(inputs)\n    model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n\n    # Freeze the pretrained weights\n    model.trainable = False\n    \n    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n    for layer in model.layers[-20:]:\n        if not isinstance(layer, layers.BatchNormalization):\n            layer.trainable = True\n\n    # Rebuild top\n    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n    x = layers.BatchNormalization()(x)\n\n    top_dropout_rate = 0.2\n    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n    outputs = layers.Dense(3, activation=\"softmax\", name=\"pred\")(x)\n\n    # Compile\n    model = tf.keras.Model(inputs, outputs, name=model_name)\n    with open(SAVE_DIR + model_name + '.h5','a') as f:\n        print(model, file=f)\n        \n    model.compile(optimizer=custom_optimizer, loss=tf.losses.CategoricalCrossentropy(), metrics=METRICS)\n    \n    return model\n\n\ndef model_EfficientNetB0_aug():\n    print(str(datetime.now()))\n    model_name = 'EfficientNetB0_aug'\n    \n    model = get_EfficientNetB0_with_aug(model_name)\n    checkPoint = define_checkPoint(model_name)\n    history = model.fit(X_train, \n                        Y_train,\n                        batch_size=batch_size_here,\n                        validation_split=0.1,\n                        epochs=epochs_size,\n                        verbose=1,\n                        callbacks=[tensorBoard, checkPoint, reduce_lr, es]\n                       )\n\n    #Evaluating the hybrid model on test data\n    test_scores = model.evaluate(X_test, Y_test)\n    print(model_name + \": Testing Accuracy of the model: %.2f%%\"%(test_scores[1] * 100))\n\n    #Print final output\n    print_output(model, history, model_name)\n\ndef model_EfficientNetB0_aug_tune():\n    print(str(datetime.now()))\n    model_name = 'EfficientNetB0_aug_tune'\n    \n    model = get_EfficientNetB0_with_aug_tune(model_name)\n    checkPoint = define_checkPoint(model_name)\n    history = model.fit(X_train, \n                        Y_train,\n                        batch_size=batch_size_here,\n                        validation_split=0.1,\n                        epochs=epochs_size,\n                        verbose=1,\n                        callbacks=[tensorBoard, checkPoint, reduce_lr, es]\n                       )\n\n    #Evaluating the hybrid model on test data\n    test_scores = model.evaluate(X_test, Y_test)\n    print(model_name + \": Testing Accuracy of the model: %.2f%%\"%(test_scores[1] * 100))\n\n    #Print final output\n    print_output(model, history, model_name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#run below 80%\n#model_EfficientNetB0_aug_tune()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#run model\nwith_augmentation = 1\nhistory = model_efficientnetb0(8)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from random import randint\n# define funtion to predict and Display Test Images result by the model\ndef predict_mri(images, labels, ready_model):\n    \n    #image class names\n    class_names =dict(zip([0,1,2,3], CLASSES))\n    print(class_names)\n    \n    plt.figure(figsize=(20, 20))\n    for i in range(16):\n        ax = plt.subplot(4, 4, i + 1)\n        indx = randint(0, 700)\n        plt.imshow(images[i])\n        \n        predictions = ready_model.predict(tf.expand_dims(images[indx], 0))\n        score = tf.nn.softmax(predictions[0])\n        \n        if(class_names[np.argmax(labels[indx])]==class_names[np.argmax(score)]):\n            plt.title(\"Actual: \"+ class_names[np.argmax(labels[indx])])\n            plt.ylabel(\"Predicted: \"+class_names[np.argmax(score)],fontdict={'color':'green'})\n\n        else:\n            plt.title(\"Actual: \" + class_names[np.argmax(labels[indx])])\n            plt.ylabel(\"Predicted: \" + class_names[np.argmax(score)],fontdict={'color':'red'})\n\n        plt.gca().axes.yaxis.set_ticklabels([])        \n        plt.gca().axes.xaxis.set_ticklabels([])\n        \n    #save plot\n    plt.savefig(SAVE_DIR + \"prediction_result.png\", bbox_inches = 'tight')\n    \n\n\ntry:    \n    #load saved model\n    saved_model = tf.keras.models.load_model('/kaggle/working/b0-CNN-8.tf')\n    # Display predicted Images\n    predict_mri(X_test, Y_test, saved_model)\nexcept Exception as e:\n    print(\"An error occurred:\", e)\nfinally:\n    print(\"Display predicted Images Done.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#print_augmented_images()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#run model\n#model_efficientnetb0(7)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#run model (97.70 with denoise + tune)\n#Tuned\n#model_efficientnetb0(4)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#run model\n#model_efficientnetb0(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#run model\n##model_EfficientNetB0_aug()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#run model\n#model_EfficientNetB0_aug_tune()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#run model\n#model_VGG16()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#run model\n#model_VGG19()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#run model\n#model_ResNet50()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#https://www.kaggle.com/general/65351\n\nimport os\nos.chdir(r'/kaggle/working')\n\n!tar -czf Landscapes.tar.gz b0-CNN-8.tf\n\nfrom IPython.display import FileLink\n\nFileLink(r'Landscapes.tar.gz')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Uploading Image and Showing its Class\ndef imagePrediction(upload):\n    for name, fileinfo  in uploader.value.items():\n        image = Image.open(io.BytesIO(fileinfo['content']))\n        \n    images = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n    images = cv2.resize(images,(150, 150))\n    images = images.reshape(1, 150, 150, 3)\n    prd = model.predict(images)\n    prd = np.argmax(prd, axis = 1)[0]\n    \n    \n    if prd == 0:\n        prd = \"CONTROL\"\n    elif prd == 1:\n        prd = \"AD\"\n    elif prd ==2:\n        prd = \"PD\"\n        \n    print(f'Model Predict That is  a {prd}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"uploader = widgets.FileUpload()\ndisplay(uploader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"##### button = widgets.Button(description= \"Predict\")\n\"\"\"\nout = widgets.Output()\n\ndef on_button_click(_):\n    with out:\n        clear_output()\n        try:\n            imagePrediction(uploader)\n        except:\n            print(\"Please Enter the Correct Image files\")\n            \n            \nbutton.on_click(on_button_click)\nwidgets.VBox([button, out])\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}